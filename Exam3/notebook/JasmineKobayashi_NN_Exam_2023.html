<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jasmine Kobayashi">

<title>CSCI 5922: Neural Networks Exam3 (Final Exam) - Fall 2023</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="JasmineKobayashi_NN_Exam_2023_files/libs/clipboard/clipboard.min.js"></script>
<script src="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/quarto.js"></script>
<script src="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/popper.min.js"></script>
<script src="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/anchor.min.js"></script>
<link href="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="JasmineKobayashi_NN_Exam_2023_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="JasmineKobayashi_NN_Exam_2023_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="JasmineKobayashi_NN_Exam_2023_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="JasmineKobayashi_NN_Exam_2023_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#part-3-applying-neural-nets-ann-cnn-lstm-to-real-labeled-text-data" id="toc-part-3-applying-neural-nets-ann-cnn-lstm-to-real-labeled-text-data" class="nav-link active" data-scroll-target="#part-3-applying-neural-nets-ann-cnn-lstm-to-real-labeled-text-data">Part 3: Applying Neural Nets (ANN, CNN, LSTM) to real labeled text data</a>
  <ul class="collapse">
  <li><a href="#the-overall-goals-here-include" id="toc-the-overall-goals-here-include" class="nav-link" data-scroll-target="#the-overall-goals-here-include">The overall goals here include:</a></li>
  <li><a href="#specific-requirements" id="toc-specific-requirements" class="nav-link" data-scroll-target="#specific-requirements">Specific requirements:</a></li>
  </ul></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data">Data</a>
  <ul class="collapse">
  <li><a href="#separate-features-targets" id="toc-separate-features-targets" class="nav-link" data-scroll-target="#separate-features-targets">Separate Features &amp; Targets</a></li>
  <li><a href="#one-hot-encoder-to-labels" id="toc-one-hot-encoder-to-labels" class="nav-link" data-scroll-target="#one-hot-encoder-to-labels">One Hot Encoder to Labels</a></li>
  <li><a href="#training-testing-sets" id="toc-training-testing-sets" class="nav-link" data-scroll-target="#training-testing-sets">Training &amp; Testing Sets</a></li>
  </ul></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  <li><a href="#ann" id="toc-ann" class="nav-link" data-scroll-target="#ann">ANN</a></li>
  <li><a href="#cnn" id="toc-cnn" class="nav-link" data-scroll-target="#cnn">CNN</a></li>
  <li><a href="#lstm" id="toc-lstm" class="nav-link" data-scroll-target="#lstm">LSTM</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">CSCI 5922: Neural Networks Exam3 (Final Exam) - Fall 2023</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jasmine Kobayashi </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="part-3-applying-neural-nets-ann-cnn-lstm-to-real-labeled-text-data" class="level1">
<h1>Part 3: Applying Neural Nets (ANN, CNN, LSTM) to real labeled text data</h1>
<p>For this part of the Exam, I have gathered articles on three topics: <em>football</em>, <em>science</em>, and <em>politics</em>. The data has already been cleaned, tokenized, and vectorized. Each row (vector) in the dataset is an article, each row is labeled as <em>football</em>, <em>science</em>, and <em>politics</em>. Each column is a word in the vocabulary. The data itself represents the number of times each word appear in that given article. (The data was gathered from <a href="https://newsapi.org/">newsapi.org</a>).</p>
<p><strong>Here is a link to the cleaned, prepared, labeled data.</strong></p>
<p><a href="https://drive.google.com/file/d/1-ZAbxWN29iCo44kaLSfYmV2E8YDKcgGE/view?usp=sharing" class="uri">https://drive.google.com/file/d/1-ZAbxWN29iCo44kaLSfYmV2E8YDKcgGE/view?usp=sharing</a></p>
<p>(If you want to know how this was done (<strong>not required</strong>) - here is code and a tutorial)</p>
<p><a href="https://gatesboltonanalytics.com/?page_id=254" class="uri">https://gatesboltonanalytics.com/?page_id=254</a></p>
<hr>
<section id="the-overall-goals-here-include" class="level2">
<h2 class="anchored" data-anchor-id="the-overall-goals-here-include">The overall goals here include:</h2>
<ol type="1">
<li>Coding, comparing, and using an ANN, CNN, and LSTM RNN in TF/Keras (Python) to Train models and to Test their accuracy.</li>
<li>You want to see if you can predict the topic of an article (in this case - <em>football</em>, <em>science</em>, and <em>politics</em>).</li>
<li>You also want to compare and illustrate the accuracy of your models and determine/discuss which model (ANN, CNN, or LSTM) is best and why this might be.</li>
<li><strong>It is up to you how to do this and how best to illustrate and explain your steps, results, and conclusions. Assume the reader is non-technical.</strong></li>
<li>You will include a <strong>link</strong> to your code, but do not paste or otherwise include code on the Exam document. (Again, you can place your code wherever you want as long as there is a link to it).</li>
</ol>
</section>
<section id="specific-requirements" class="level2">
<h2 class="anchored" data-anchor-id="specific-requirements">Specific requirements:</h2>
<p>There are many ways to do this. The following offeres a few core requirements. Beyond this, <strong>YOU must decide what to do and how best to do it.</strong> Part of your grade will be based on your flow, discussion, illustrations, report, and communication of methods and results. Again, you will post a link to the code, but you will not include or paste code in the word doc.</p>
<ol type="1">
<li><p>Use Python and TF/Keras to Train and then Test the accuracy for an ANN, CNN, and LSTM RNN. In other words, you will use three different Neural Networks to create models that should predict whether a test vector (which represents an article on a topic) is on the topic of <em>science</em>, <em>football</em>, or <em>politics</em>. You will need to write code to do this. You already have code for ANNs, CNNs, and LSTM RNNs, so you may choose to repurpose/update your code as needed.</p></li>
<li><p>To show your work and to <strong>illustrate and explain</strong> your work, results, and conclusions you must include at least the following:</p>
<ol type="a">
<li><p>A link to your code. If you wish, you can put your code on your website, Google Colab, GitHub or wherever, an the include the URL on the word doc.</p></li>
<li><p>Show and explain how you <strong>prepared the data</strong> so that you can use it properly to Train and Test your models. (You are not required to validate - but you certainly can). Specifically, if you split the data, discuss and illustrate this. If you encode the labels, discuss and illustrate this, etc. Use images (like screenshots) as needed. YOU decide and explain/show what you are doing.</p></li>
<li><p><strong>DO NOT</strong> include or paste any code (to Word doc). You do not need nor should you use “code” to explain or illustrate what you are doing. Use illustrations, images, explanations. Pretend that the person grading this paper does not know Python but does wan to see and understand what you did, what you found, how your models compare, which model worked best, etc.</p></li>
<li><p>TO be clear - You will be coding, training, and then testing three types of models: ANN, CNN, LSTM. Therefore, you should include screen images (small portions) of the training for each (a few of the last epochs), as well as <strong>confusion matrices</strong> for each that illustrate the test data accuracy for each model.</p></li>
<li><p>Discuss and describe what you are doing and showing.</p></li>
<li><p>Discuss and illustrate the results. Which model worked best (have confusion matrices that support this discussion). Comment on which model you expected to work the best, which model actually worked the best and why.</p></li>
</ol></li>
</ol>
<hr>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os,sys</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow.keras</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> LSTM, Dense, Dropout, LSTM</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-12-09 08:28:12.733515: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-12-09 08:28:12.783324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% working directory</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"current working directory:"</span>, os.getcwd())</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.getcwd()[<span class="op">-</span><span class="dv">15</span>:] <span class="op">!=</span> <span class="st">"/CSCI5922/Exam3"</span>:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    src_file_dir <span class="op">=</span> os.path.abspath(<span class="st">""</span>)          <span class="co"># directory holding this script file</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    src_dir <span class="op">=</span> os.path.dirname(src_file_dir)     <span class="co"># parent directory of above directory</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    os.chdir(src_dir)                           <span class="co"># working directory should now be ".../CSCI5922/Exam3"</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"current working directory:"</span>, os.getcwd())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>current working directory: /home/jasminekobayashi/gh_repos/CSCI5922/Exam3/notebook
current working directory: /home/jasminekobayashi/gh_repos/CSCI5922/Exam3</code></pre>
</div>
</div>
</section>
</section>
<section id="data" class="level1">
<h1>Data</h1>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% load data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"data/Final_News_DF_Labeled_ExamDataset.csv"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">LABEL</th>
<th data-quarto-table-cell-role="th">according</th>
<th data-quarto-table-cell-role="th">agency</th>
<th data-quarto-table-cell-role="th">ahead</th>
<th data-quarto-table-cell-role="th">alabama</th>
<th data-quarto-table-cell-role="th">amazon</th>
<th data-quarto-table-cell-role="th">america</th>
<th data-quarto-table-cell-role="th">american</th>
<th data-quarto-table-cell-role="th">announced</th>
<th data-quarto-table-cell-role="th">appeared</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">wolverines</th>
<th data-quarto-table-cell-role="th">women</th>
<th data-quarto-table-cell-role="th">work</th>
<th data-quarto-table-cell-role="th">working</th>
<th data-quarto-table-cell-role="th">world</th>
<th data-quarto-table-cell-role="th">wrote</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">years</th>
<th data-quarto-table-cell-role="th">york</th>
<th data-quarto-table-cell-role="th">young</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>politics</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>politics</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>politics</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>politics</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>politics</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>5 rows × 301 columns</p>
</div>
</div>
</div>
<section id="separate-features-targets" class="level2">
<h2 class="anchored" data-anchor-id="separate-features-targets">Separate Features &amp; Targets</h2>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% features vs. targets (aka: estimators vs. predictors, input vs. output, etc.)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop(columns<span class="op">=</span>[<span class="st">'LABEL'</span>]).to_numpy()     <span class="co"># features: everything except column "LABEL"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[[<span class="st">"LABEL"</span>]]                             <span class="co"># targets: column "LABEL"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview of X (first 5 rows)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>X[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 1, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview of y</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">LABEL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>politics</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>politics</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>politics</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>politics</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>politics</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="one-hot-encoder-to-labels" class="level2">
<h2 class="anchored" data-anchor-id="one-hot-encoder-to-labels">One Hot Encoder to Labels</h2>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% One Hot encode label</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>OHE <span class="op">=</span> OneHotEncoder()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> OHE.fit_transform(y).toarray()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>OHE.categories_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>[array(['football', 'politics', 'science'], dtype=object)]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview one hot encoded y</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[0., 1., 0.],
       [0., 1., 0.],
       [0., 1., 0.],
       [0., 1., 0.],
       [0., 1., 0.]])</code></pre>
</div>
</div>
</section>
<section id="training-testing-sets" class="level2">
<h2 class="anchored" data-anchor-id="training-testing-sets">Training &amp; Testing Sets</h2>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># %% Training &amp; Testing set</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>test_size <span class="op">=</span> <span class="fl">0.2</span> <span class="co"># what percent of the data = testing set </span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>X_train,X_test,y_train,y_test <span class="op">=</span> train_test_split(X,y,test_size<span class="op">=</span>test_size,random_state<span class="op">=</span><span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview X_train (first 5 rows)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>X_train[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview y_train</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>y_train[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>array([[0., 1., 0.],
       [0., 0., 1.],
       [0., 1., 0.],
       [1., 0., 0.],
       [1., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test inverse transform of One-Hot Encoder</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>OHE.inverse_transform(y_train[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>array([['politics'],
       ['science'],
       ['politics'],
       ['football'],
       ['football']], dtype=object)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview X_test</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>X_test[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [1, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview y_test</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y_test[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>array([[0., 0., 1.],
       [0., 1., 0.],
       [0., 1., 0.],
       [0., 1., 0.],
       [1., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preview OHE inverse transform on y_test</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>OHE.inverse_transform(y_test[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([['science'],
       ['politics'],
       ['politics'],
       ['politics'],
       ['football']], dtype=object)</code></pre>
</div>
</div>
</section>
</section>
<section id="models" class="level1">
<h1>Models</h1>
<p>There are some portions of the code that could be relatively repetitive, so rather than just constantly copy and pasting cell codes, I created the following class to help with some redundancy.</p>
<p>The class is built so that after building the model, the desired model to be evaluated is passed into the class when instantiated (and the model summary is outputted during instantiation).</p>
<p>It contains functions that simplify some repetitive process with parameters to change the small details to give flexibility to change if needed depending on the model. Some function may default to have some useful informative outputs (like what loss function was used, data previews, etc.).</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> exam_model_eval:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,NN_model,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                 model_name <span class="op">=</span> <span class="st">'NN Model'</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                 X_train<span class="op">=</span>X_train,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>                 X_test<span class="op">=</span>X_test,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                 y_train<span class="op">=</span>y_train,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                 y_test<span class="op">=</span>y_test,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>                 OHE<span class="op">=</span>OHE):</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.NN_model <span class="op">=</span> NN_model</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_name <span class="op">=</span> model_name</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.OHE <span class="op">=</span> OHE</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_train <span class="op">=</span> X_train</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_test <span class="op">=</span> X_test</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_train <span class="op">=</span> y_train</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labeled_y_train <span class="op">=</span> <span class="va">self</span>.OHE.inverse_transform(<span class="va">self</span>.y_train) <span class="co">#likely not needed, but potentially useful</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_test <span class="op">=</span> y_test</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labeled_y_test <span class="op">=</span> <span class="va">self</span>.OHE.inverse_transform(<span class="va">self</span>.y_test)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print model summary</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="va">self</span>.NN_model.summary())</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compile_model(<span class="va">self</span>, </span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>                      loss <span class="op">=</span> tf.keras.losses.CategoricalCrossentropy(),</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>                      metrics <span class="op">=</span> keras.metrics.CategoricalAccuracy(),</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>                      optimizer <span class="op">=</span> tf.keras.optimizers.legacy.Adam(learning_rate <span class="op">=</span> <span class="fl">0.001</span>)):</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.NN_model.<span class="bu">compile</span>(loss<span class="op">=</span>loss,</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>                              metrics <span class="op">=</span> metrics,</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>                              optimizer <span class="op">=</span> optimizer)</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Model was compiled (using following parameters):"</span>)</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Loss Function ="</span>,<span class="bu">str</span>(loss))</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Accuracy Metric ="</span>,<span class="bu">str</span>(metrics))</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Optimizer ="</span>,<span class="bu">str</span>(optimizer))</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_model(<span class="va">self</span>,epochs <span class="op">=</span> <span class="dv">10</span>):</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hist <span class="op">=</span> <span class="va">self</span>.NN_model.fit(<span class="va">self</span>.X_train,</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>                                         <span class="va">self</span>.y_train,</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>                                         epochs <span class="op">=</span> epochs,</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>                                         validation_data <span class="op">=</span>(<span class="va">self</span>.X_test,<span class="va">self</span>.y_test))</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> accuracy_plot(<span class="va">self</span>,</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>                      title <span class="op">=</span> <span class="st">"Accuracy over all Epochs"</span>):</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Accuracy plot</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="va">self</span>.hist.history[<span class="st">'categorical_accuracy'</span>], label<span class="op">=</span><span class="st">'accuracy'</span>)</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="va">self</span>.hist.history[<span class="st">'val_categorical_accuracy'</span>], label <span class="op">=</span> <span class="st">'val_accuracy'</span>)</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>        plt.title(title<span class="op">+</span><span class="st">" for </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(<span class="va">self</span>.model_name))</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>        <span class="co">#plt.ylim([0.5, 1])</span></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>        plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loss_plot(<span class="va">self</span>,</span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>                  title <span class="op">=</span> <span class="st">"Loss over all epochs"</span>):</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loss plot</span></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="va">self</span>.hist.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="st">'loss'</span>)</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="va">self</span>.hist.history[<span class="st">'val_loss'</span>], label <span class="op">=</span> <span class="st">'val_loss'</span>)</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>        plt.title(title<span class="op">+</span><span class="st">" for </span><span class="sc">{}</span><span class="st"> "</span>.<span class="bu">format</span>(<span class="va">self</span>.model_name))</span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>        <span class="co">#plt.ylim([0.5, 1])</span></span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>        plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> test_model(<span class="va">self</span>,verbose<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prediction <span class="op">=</span> <span class="va">self</span>.NN_model.predict(<span class="va">self</span>.X_test)</span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labeled_prediction <span class="op">=</span> <span class="va">self</span>.OHE.inverse_transform(<span class="va">self</span>.prediction)</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eval_loss,<span class="va">self</span>.eval_acc <span class="op">=</span> <span class="va">self</span>.NN_model.evaluate(<span class="va">self</span>.X_test,<span class="va">self</span>.y_test)</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> verbose:</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model Loss from testing:"</span>)</span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="va">self</span>.eval_loss)</span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model Accuracy from testing:"</span>)</span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="va">self</span>.eval_acc)</span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Preview of model prediction (raw):"</span>)</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="va">self</span>.prediction[:<span class="dv">5</span>])</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Preview of predictions labeled:"</span>)</span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="va">self</span>.labeled_prediction[:<span class="dv">5</span>])</span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pretty_confusion_matrix(<span class="va">self</span>,</span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a>                                title<span class="op">=</span><span class="st">'Confusion Matrix'</span>):</span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(<span class="va">self</span>.labeled_prediction,<span class="va">self</span>.labeled_y_test)</span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a>        fig, ax <span class="op">=</span> plt.subplots() </span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a>        sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'g'</span>, ax<span class="op">=</span>ax, annot_kws<span class="op">=</span>{<span class="st">'size'</span>: <span class="dv">18</span>})</span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a>        ax.set_xlabel(<span class="st">'True labels'</span>) </span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a>        ax.set_ylabel(<span class="st">'Predicted labels'</span>)</span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a>        ax.xaxis.set_ticklabels(<span class="va">self</span>.OHE.categories_[<span class="dv">0</span>].tolist())</span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a>        ax.yaxis.set_ticklabels(<span class="va">self</span>.OHE.categories_[<span class="dv">0</span>].tolist())</span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title<span class="op">+</span><span class="st">" of </span><span class="sc">{}</span><span class="st"> Prediction Performance"</span>.<span class="bu">format</span>(<span class="va">self</span>.model_name)) </span>
<span id="cb28-96"><a href="#cb28-96" aria-hidden="true" tabindex="-1"></a>        plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-12-09 08:28:15.351229: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: UNKNOWN ERROR (100)</code></pre>
</div>
</div>
</section>
<section id="ann" class="level1">
<h1>ANN</h1>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>ANN_model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>), </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">16</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dropout(<span class="fl">.5</span>), </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">8</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dropout(<span class="fl">.5</span>), </span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>ANN_model(X_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>&lt;tf.Tensor: shape=(1194, 3), dtype=float32, numpy=
array([[0.33639392, 0.36515632, 0.2984497 ],
       [0.33902603, 0.332783  , 0.3281909 ],
       [0.3349162 , 0.3355176 , 0.32956624],
       ...,
       [0.3373453 , 0.33507353, 0.3275812 ],
       [0.33695954, 0.3388812 , 0.32415926],
       [0.35172728, 0.29831308, 0.3499597 ]], dtype=float32)&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>my_ANN <span class="op">=</span> exam_model_eval(ANN_model,model_name<span class="op">=</span><span class="st">"ANN_model"</span>) <span class="co">#the init of this class prints the model summary</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (1194, 32)                9632      
                                                                 
 dense_1 (Dense)             (1194, 16)                528       
                                                                 
 dropout (Dropout)           (1194, 16)                0         
                                                                 
 dense_2 (Dense)             (1194, 8)                 136       
                                                                 
 dropout_1 (Dropout)         (1194, 8)                 0         
                                                                 
 dense_3 (Dense)             (1194, 3)                 27        
                                                                 
=================================================================
Total params: 10,323
Trainable params: 10,323
Non-trainable params: 0
_________________________________________________________________
None</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>my_ANN.compile_model()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model was compiled (using following parameters):
Loss Function = &lt;keras.losses.CategoricalCrossentropy object at 0x7f5ef098e010&gt;
Accuracy Metric = CategoricalAccuracy(name=categorical_accuracy,dtype=float32)
Optimizer = &lt;keras.optimizers.legacy.adam.Adam object at 0x7f5ef0965110&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>my_ANN.train_model(epochs<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
30/38 [======================&gt;.......] - ETA: 0s - loss: 1.0936 - categorical_accuracy: 0.338538/38 [==============================] - 1s 13ms/step - loss: 1.0886 - categorical_accuracy: 0.3509 - val_loss: 1.0803 - val_categorical_accuracy: 0.3980
Epoch 2/100
38/38 [==============================] - 0s 5ms/step - loss: 1.0642 - categorical_accuracy: 0.3886 - val_loss: 1.0619 - val_categorical_accuracy: 0.4649
Epoch 3/100
38/38 [==============================] - 0s 5ms/step - loss: 1.0531 - categorical_accuracy: 0.4196 - val_loss: 1.0441 - val_categorical_accuracy: 0.4816
Epoch 4/100
38/38 [==============================] - 0s 6ms/step - loss: 1.0373 - categorical_accuracy: 0.4380 - val_loss: 1.0201 - val_categorical_accuracy: 0.5385
Epoch 5/100
38/38 [==============================] - 0s 8ms/step - loss: 1.0045 - categorical_accuracy: 0.4615 - val_loss: 0.9893 - val_categorical_accuracy: 0.5652
Epoch 6/100
38/38 [==============================] - 0s 7ms/step - loss: 0.9777 - categorical_accuracy: 0.5042 - val_loss: 0.9481 - val_categorical_accuracy: 0.6321
Epoch 7/100
38/38 [==============================] - 0s 8ms/step - loss: 0.9180 - categorical_accuracy: 0.5519 - val_loss: 0.8871 - val_categorical_accuracy: 0.6455
Epoch 8/100
38/38 [==============================] - 0s 4ms/step - loss: 0.8931 - categorical_accuracy: 0.5452 - val_loss: 0.8462 - val_categorical_accuracy: 0.6789
Epoch 9/100
38/38 [==============================] - 0s 7ms/step - loss: 0.8488 - categorical_accuracy: 0.5754 - val_loss: 0.8071 - val_categorical_accuracy: 0.7057
Epoch 10/100
38/38 [==============================] - 0s 5ms/step - loss: 0.7976 - categorical_accuracy: 0.6265 - val_loss: 0.7731 - val_categorical_accuracy: 0.7057
Epoch 11/100
38/38 [==============================] - 0s 4ms/step - loss: 0.7485 - categorical_accuracy: 0.6524 - val_loss: 0.7426 - val_categorical_accuracy: 0.7291
Epoch 12/100
38/38 [==============================] - 0s 5ms/step - loss: 0.7252 - categorical_accuracy: 0.6742 - val_loss: 0.7303 - val_categorical_accuracy: 0.7324
Epoch 13/100
38/38 [==============================] - 0s 5ms/step - loss: 0.7184 - categorical_accuracy: 0.6859 - val_loss: 0.7193 - val_categorical_accuracy: 0.7258
Epoch 14/100
38/38 [==============================] - 0s 4ms/step - loss: 0.6984 - categorical_accuracy: 0.7060 - val_loss: 0.7175 - val_categorical_accuracy: 0.7157
Epoch 15/100
38/38 [==============================] - 0s 6ms/step - loss: 0.6603 - categorical_accuracy: 0.7312 - val_loss: 0.7074 - val_categorical_accuracy: 0.7324
Epoch 16/100
38/38 [==============================] - 0s 4ms/step - loss: 0.6344 - categorical_accuracy: 0.7412 - val_loss: 0.7074 - val_categorical_accuracy: 0.7358
Epoch 17/100
38/38 [==============================] - 0s 4ms/step - loss: 0.6148 - categorical_accuracy: 0.7580 - val_loss: 0.7128 - val_categorical_accuracy: 0.7391
Epoch 18/100
38/38 [==============================] - 0s 7ms/step - loss: 0.6362 - categorical_accuracy: 0.7496 - val_loss: 0.7238 - val_categorical_accuracy: 0.7191
Epoch 19/100
38/38 [==============================] - 0s 5ms/step - loss: 0.5817 - categorical_accuracy: 0.7764 - val_loss: 0.7284 - val_categorical_accuracy: 0.7425
Epoch 20/100
38/38 [==============================] - 0s 6ms/step - loss: 0.5778 - categorical_accuracy: 0.7747 - val_loss: 0.7470 - val_categorical_accuracy: 0.7324
Epoch 21/100
38/38 [==============================] - 0s 5ms/step - loss: 0.5782 - categorical_accuracy: 0.7789 - val_loss: 0.7481 - val_categorical_accuracy: 0.7425
Epoch 22/100
38/38 [==============================] - 0s 4ms/step - loss: 0.5458 - categorical_accuracy: 0.8015 - val_loss: 0.7645 - val_categorical_accuracy: 0.7291
Epoch 23/100
38/38 [==============================] - 0s 5ms/step - loss: 0.5468 - categorical_accuracy: 0.7973 - val_loss: 0.7921 - val_categorical_accuracy: 0.7291
Epoch 24/100
38/38 [==============================] - 0s 6ms/step - loss: 0.5230 - categorical_accuracy: 0.7990 - val_loss: 0.7941 - val_categorical_accuracy: 0.7324
Epoch 25/100
38/38 [==============================] - 0s 5ms/step - loss: 0.5219 - categorical_accuracy: 0.7881 - val_loss: 0.8408 - val_categorical_accuracy: 0.7291
Epoch 26/100
38/38 [==============================] - 0s 7ms/step - loss: 0.5021 - categorical_accuracy: 0.8166 - val_loss: 0.8413 - val_categorical_accuracy: 0.7324
Epoch 27/100
38/38 [==============================] - 0s 8ms/step - loss: 0.5056 - categorical_accuracy: 0.8174 - val_loss: 0.8443 - val_categorical_accuracy: 0.7224
Epoch 28/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4816 - categorical_accuracy: 0.8308 - val_loss: 0.8814 - val_categorical_accuracy: 0.7258
Epoch 29/100
38/38 [==============================] - 0s 5ms/step - loss: 0.4739 - categorical_accuracy: 0.8375 - val_loss: 0.9235 - val_categorical_accuracy: 0.7258
Epoch 30/100
38/38 [==============================] - 0s 5ms/step - loss: 0.4822 - categorical_accuracy: 0.8258 - val_loss: 0.9275 - val_categorical_accuracy: 0.7224
Epoch 31/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4411 - categorical_accuracy: 0.8451 - val_loss: 0.9648 - val_categorical_accuracy: 0.7258
Epoch 32/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4278 - categorical_accuracy: 0.8543 - val_loss: 0.9675 - val_categorical_accuracy: 0.7224
Epoch 33/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4515 - categorical_accuracy: 0.8358 - val_loss: 0.9986 - val_categorical_accuracy: 0.7324
Epoch 34/100
38/38 [==============================] - 0s 6ms/step - loss: 0.4266 - categorical_accuracy: 0.8476 - val_loss: 1.0242 - val_categorical_accuracy: 0.7224
Epoch 35/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4148 - categorical_accuracy: 0.8509 - val_loss: 1.0299 - val_categorical_accuracy: 0.7191
Epoch 36/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4461 - categorical_accuracy: 0.8384 - val_loss: 1.0403 - val_categorical_accuracy: 0.7191
Epoch 37/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4371 - categorical_accuracy: 0.8484 - val_loss: 1.1051 - val_categorical_accuracy: 0.7124
Epoch 38/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4069 - categorical_accuracy: 0.8585 - val_loss: 1.1337 - val_categorical_accuracy: 0.7191
Epoch 39/100
38/38 [==============================] - 0s 4ms/step - loss: 0.4093 - categorical_accuracy: 0.8534 - val_loss: 1.1303 - val_categorical_accuracy: 0.7258
Epoch 40/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3992 - categorical_accuracy: 0.8585 - val_loss: 1.1232 - val_categorical_accuracy: 0.7358
Epoch 41/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3904 - categorical_accuracy: 0.8643 - val_loss: 1.1241 - val_categorical_accuracy: 0.7191
Epoch 42/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3953 - categorical_accuracy: 0.8618 - val_loss: 1.1692 - val_categorical_accuracy: 0.7258
Epoch 43/100
38/38 [==============================] - 0s 4ms/step - loss: 0.3876 - categorical_accuracy: 0.8652 - val_loss: 1.1879 - val_categorical_accuracy: 0.7191
Epoch 44/100
38/38 [==============================] - 0s 7ms/step - loss: 0.4050 - categorical_accuracy: 0.8492 - val_loss: 1.1786 - val_categorical_accuracy: 0.7391
Epoch 45/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3718 - categorical_accuracy: 0.8702 - val_loss: 1.2542 - val_categorical_accuracy: 0.7291
Epoch 46/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3618 - categorical_accuracy: 0.8777 - val_loss: 1.2513 - val_categorical_accuracy: 0.7258
Epoch 47/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3787 - categorical_accuracy: 0.8693 - val_loss: 1.2316 - val_categorical_accuracy: 0.7224
Epoch 48/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3607 - categorical_accuracy: 0.8719 - val_loss: 1.2455 - val_categorical_accuracy: 0.7291
Epoch 49/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3496 - categorical_accuracy: 0.8744 - val_loss: 1.2849 - val_categorical_accuracy: 0.7324
Epoch 50/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3779 - categorical_accuracy: 0.8635 - val_loss: 1.3773 - val_categorical_accuracy: 0.7258
Epoch 51/100
38/38 [==============================] - 0s 9ms/step - loss: 0.3632 - categorical_accuracy: 0.8635 - val_loss: 1.3475 - val_categorical_accuracy: 0.7425
Epoch 52/100
38/38 [==============================] - 0s 4ms/step - loss: 0.3493 - categorical_accuracy: 0.8769 - val_loss: 1.4171 - val_categorical_accuracy: 0.7191
Epoch 53/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3359 - categorical_accuracy: 0.8827 - val_loss: 1.4491 - val_categorical_accuracy: 0.7324
Epoch 54/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3484 - categorical_accuracy: 0.8702 - val_loss: 1.4260 - val_categorical_accuracy: 0.7291
Epoch 55/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3485 - categorical_accuracy: 0.8786 - val_loss: 1.4463 - val_categorical_accuracy: 0.7391
Epoch 56/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3646 - categorical_accuracy: 0.8652 - val_loss: 1.4501 - val_categorical_accuracy: 0.7324
Epoch 57/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3395 - categorical_accuracy: 0.8760 - val_loss: 1.4799 - val_categorical_accuracy: 0.7324
Epoch 58/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3586 - categorical_accuracy: 0.8635 - val_loss: 1.5004 - val_categorical_accuracy: 0.7324
Epoch 59/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3330 - categorical_accuracy: 0.8827 - val_loss: 1.5260 - val_categorical_accuracy: 0.7358
Epoch 60/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3118 - categorical_accuracy: 0.8903 - val_loss: 1.5508 - val_categorical_accuracy: 0.7358
Epoch 61/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3518 - categorical_accuracy: 0.8719 - val_loss: 1.5392 - val_categorical_accuracy: 0.7391
Epoch 62/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3338 - categorical_accuracy: 0.8836 - val_loss: 1.5909 - val_categorical_accuracy: 0.7358
Epoch 63/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3500 - categorical_accuracy: 0.8786 - val_loss: 1.5701 - val_categorical_accuracy: 0.7358
Epoch 64/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3301 - categorical_accuracy: 0.8844 - val_loss: 1.6411 - val_categorical_accuracy: 0.7124
Epoch 65/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3424 - categorical_accuracy: 0.8735 - val_loss: 1.5940 - val_categorical_accuracy: 0.7291
Epoch 66/100
38/38 [==============================] - 0s 4ms/step - loss: 0.3321 - categorical_accuracy: 0.8786 - val_loss: 1.6276 - val_categorical_accuracy: 0.7191
Epoch 67/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3343 - categorical_accuracy: 0.8777 - val_loss: 1.7029 - val_categorical_accuracy: 0.7124
Epoch 68/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3196 - categorical_accuracy: 0.8886 - val_loss: 1.6533 - val_categorical_accuracy: 0.7258
Epoch 69/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3394 - categorical_accuracy: 0.8802 - val_loss: 1.6680 - val_categorical_accuracy: 0.7224
Epoch 70/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3261 - categorical_accuracy: 0.8827 - val_loss: 1.7546 - val_categorical_accuracy: 0.7090
Epoch 71/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3293 - categorical_accuracy: 0.8777 - val_loss: 1.7522 - val_categorical_accuracy: 0.7191
Epoch 72/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3160 - categorical_accuracy: 0.8894 - val_loss: 1.8022 - val_categorical_accuracy: 0.7157
Epoch 73/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3086 - categorical_accuracy: 0.8802 - val_loss: 1.8711 - val_categorical_accuracy: 0.7191
Epoch 74/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3068 - categorical_accuracy: 0.8920 - val_loss: 1.9489 - val_categorical_accuracy: 0.7157
Epoch 75/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3196 - categorical_accuracy: 0.8836 - val_loss: 1.8622 - val_categorical_accuracy: 0.7224
Epoch 76/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3090 - categorical_accuracy: 0.8945 - val_loss: 1.9031 - val_categorical_accuracy: 0.7224
Epoch 77/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3049 - categorical_accuracy: 0.8928 - val_loss: 1.9041 - val_categorical_accuracy: 0.7358
Epoch 78/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3240 - categorical_accuracy: 0.8827 - val_loss: 1.9770 - val_categorical_accuracy: 0.7291
Epoch 79/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3334 - categorical_accuracy: 0.8794 - val_loss: 1.9452 - val_categorical_accuracy: 0.7291
Epoch 80/100
38/38 [==============================] - 0s 7ms/step - loss: 0.2960 - categorical_accuracy: 0.8978 - val_loss: 2.0748 - val_categorical_accuracy: 0.7090
Epoch 81/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3080 - categorical_accuracy: 0.8878 - val_loss: 2.0508 - val_categorical_accuracy: 0.7023
Epoch 82/100
38/38 [==============================] - 0s 4ms/step - loss: 0.3125 - categorical_accuracy: 0.8861 - val_loss: 2.0893 - val_categorical_accuracy: 0.7124
Epoch 83/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3236 - categorical_accuracy: 0.8827 - val_loss: 2.0682 - val_categorical_accuracy: 0.7191
Epoch 84/100
38/38 [==============================] - 0s 6ms/step - loss: 0.2968 - categorical_accuracy: 0.8936 - val_loss: 2.0701 - val_categorical_accuracy: 0.7191
Epoch 85/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3103 - categorical_accuracy: 0.8886 - val_loss: 2.0670 - val_categorical_accuracy: 0.7124
Epoch 86/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3321 - categorical_accuracy: 0.8811 - val_loss: 2.0447 - val_categorical_accuracy: 0.7191
Epoch 87/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3153 - categorical_accuracy: 0.8869 - val_loss: 2.1840 - val_categorical_accuracy: 0.7090
Epoch 88/100
38/38 [==============================] - 0s 7ms/step - loss: 0.3118 - categorical_accuracy: 0.8853 - val_loss: 2.1915 - val_categorical_accuracy: 0.7124
Epoch 89/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3227 - categorical_accuracy: 0.8786 - val_loss: 2.1514 - val_categorical_accuracy: 0.7224
Epoch 90/100
38/38 [==============================] - 0s 4ms/step - loss: 0.3048 - categorical_accuracy: 0.8903 - val_loss: 2.2270 - val_categorical_accuracy: 0.7124
Epoch 91/100
38/38 [==============================] - 0s 4ms/step - loss: 0.2922 - categorical_accuracy: 0.8936 - val_loss: 2.2383 - val_categorical_accuracy: 0.7090
Epoch 92/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3378 - categorical_accuracy: 0.8760 - val_loss: 2.2931 - val_categorical_accuracy: 0.7057
Epoch 93/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3155 - categorical_accuracy: 0.8836 - val_loss: 2.2348 - val_categorical_accuracy: 0.7191
Epoch 94/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3091 - categorical_accuracy: 0.8869 - val_loss: 2.2954 - val_categorical_accuracy: 0.7124
Epoch 95/100
38/38 [==============================] - 0s 4ms/step - loss: 0.2939 - categorical_accuracy: 0.8911 - val_loss: 2.2858 - val_categorical_accuracy: 0.7258
Epoch 96/100
38/38 [==============================] - 0s 6ms/step - loss: 0.3181 - categorical_accuracy: 0.8811 - val_loss: 2.3571 - val_categorical_accuracy: 0.7191
Epoch 97/100
38/38 [==============================] - 0s 8ms/step - loss: 0.3174 - categorical_accuracy: 0.8878 - val_loss: 2.3214 - val_categorical_accuracy: 0.7324
Epoch 98/100
38/38 [==============================] - 0s 7ms/step - loss: 0.2988 - categorical_accuracy: 0.8945 - val_loss: 2.4039 - val_categorical_accuracy: 0.7124
Epoch 99/100
38/38 [==============================] - 0s 7ms/step - loss: 0.2930 - categorical_accuracy: 0.8995 - val_loss: 2.4856 - val_categorical_accuracy: 0.7023
Epoch 100/100
38/38 [==============================] - 0s 5ms/step - loss: 0.3039 - categorical_accuracy: 0.8844 - val_loss: 2.3689 - val_categorical_accuracy: 0.7157
CPU times: user 29.9 s, sys: 8.8 s, total: 38.8 s
Wall time: 25.2 s</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>my_ANN.accuracy_plot()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>my_ANN.loss_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-23-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>my_ANN.test_model(verbose<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 0s 2ms/step
10/10 [==============================] - 0s 3ms/step - loss: 2.3689 - categorical_accuracy: 0.7157

Model Loss from testing:
2.3688647747039795

Model Accuracy from testing:
0.7157190442085266

Preview of model prediction (raw):
[[0.1059913  0.07910823 0.8149005 ]
 [0.8501408  0.02856642 0.12129278]
 [0.02549611 0.96391344 0.01059047]
 [0.00786874 0.98966557 0.00246572]
 [1.         0.         0.        ]]

Preview of predictions labeled:
[['science']
 ['football']
 ['politics']
 ['politics']
 ['football']]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>my_ANN.pretty_confusion_matrix()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="cnn" class="level1">
<h1>CNN</h1>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>input_dim <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>input_shape <span class="op">=</span> (input_dim,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>CNN_model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Conv1D(<span class="dv">50</span>,input_shape <span class="op">=</span> input_shape, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Conv1D(<span class="dv">40</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Conv1D(<span class="dv">30</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Conv1D(<span class="dv">30</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.MaxPool1D(pool_size<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Flatten(),</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">20</span>),</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>my_CNN <span class="op">=</span> exam_model_eval(CNN_model,model_name<span class="op">=</span><span class="st">"CNN Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv1d (Conv1D)             (None, 298, 50)           200       
                                                                 
 max_pooling1d (MaxPooling1D  (None, 149, 50)          0         
 )                                                               
                                                                 
 conv1d_1 (Conv1D)           (None, 147, 40)           6040      
                                                                 
 max_pooling1d_1 (MaxPooling  (None, 73, 40)           0         
 1D)                                                             
                                                                 
 conv1d_2 (Conv1D)           (None, 71, 30)            3630      
                                                                 
 max_pooling1d_2 (MaxPooling  (None, 35, 30)           0         
 1D)                                                             
                                                                 
 conv1d_3 (Conv1D)           (None, 33, 30)            2730      
                                                                 
 max_pooling1d_3 (MaxPooling  (None, 16, 30)           0         
 1D)                                                             
                                                                 
 flatten (Flatten)           (None, 480)               0         
                                                                 
 dense_4 (Dense)             (None, 20)                9620      
                                                                 
 dropout_2 (Dropout)         (None, 20)                0         
                                                                 
 dense_5 (Dense)             (None, 3)                 63        
                                                                 
=================================================================
Total params: 22,283
Trainable params: 22,283
Non-trainable params: 0
_________________________________________________________________
None</code></pre>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>my_CNN.compile_model()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model was compiled (using following parameters):
Loss Function = &lt;keras.losses.CategoricalCrossentropy object at 0x7f5ef098e010&gt;
Accuracy Metric = CategoricalAccuracy(name=categorical_accuracy,dtype=float32)
Optimizer = &lt;keras.optimizers.legacy.adam.Adam object at 0x7f5ef0965110&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>my_CNN.train_model(epochs<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
38/38 [==============================] - 2s 28ms/step - loss: 0.9773 - categorical_accuracy: 0.5439 - val_loss: 0.8874 - val_categorical_accuracy: 0.5886
Epoch 2/100
38/38 [==============================] - 1s 14ms/step - loss: 0.8164 - categorical_accuracy: 0.6189 - val_loss: 0.7965 - val_categorical_accuracy: 0.6421
Epoch 3/100
38/38 [==============================] - 1s 18ms/step - loss: 0.7233 - categorical_accuracy: 0.6809 - val_loss: 0.7786 - val_categorical_accuracy: 0.6488
Epoch 4/100
38/38 [==============================] - 1s 15ms/step - loss: 0.6471 - categorical_accuracy: 0.7186 - val_loss: 0.7619 - val_categorical_accuracy: 0.6789
Epoch 5/100
38/38 [==============================] - 1s 15ms/step - loss: 0.6357 - categorical_accuracy: 0.7295 - val_loss: 0.7255 - val_categorical_accuracy: 0.7057
Epoch 6/100
38/38 [==============================] - 1s 14ms/step - loss: 0.5864 - categorical_accuracy: 0.7538 - val_loss: 0.7637 - val_categorical_accuracy: 0.6856
Epoch 7/100
38/38 [==============================] - 1s 15ms/step - loss: 0.5755 - categorical_accuracy: 0.7714 - val_loss: 0.7523 - val_categorical_accuracy: 0.6789
Epoch 8/100
38/38 [==============================] - 1s 16ms/step - loss: 0.5565 - categorical_accuracy: 0.7638 - val_loss: 0.7314 - val_categorical_accuracy: 0.6957
Epoch 9/100
38/38 [==============================] - 1s 17ms/step - loss: 0.5273 - categorical_accuracy: 0.7755 - val_loss: 0.7402 - val_categorical_accuracy: 0.6856
Epoch 10/100
38/38 [==============================] - 1s 18ms/step - loss: 0.5304 - categorical_accuracy: 0.7697 - val_loss: 0.7599 - val_categorical_accuracy: 0.6756
Epoch 11/100
38/38 [==============================] - 1s 21ms/step - loss: 0.5014 - categorical_accuracy: 0.7982 - val_loss: 0.7742 - val_categorical_accuracy: 0.6756
Epoch 12/100
38/38 [==============================] - 1s 20ms/step - loss: 0.4889 - categorical_accuracy: 0.7948 - val_loss: 0.7996 - val_categorical_accuracy: 0.6856
Epoch 13/100
38/38 [==============================] - 1s 16ms/step - loss: 0.4788 - categorical_accuracy: 0.7923 - val_loss: 0.7980 - val_categorical_accuracy: 0.6823
Epoch 14/100
38/38 [==============================] - 1s 15ms/step - loss: 0.4575 - categorical_accuracy: 0.7998 - val_loss: 0.8298 - val_categorical_accuracy: 0.6722
Epoch 15/100
38/38 [==============================] - 1s 17ms/step - loss: 0.4578 - categorical_accuracy: 0.8057 - val_loss: 0.8413 - val_categorical_accuracy: 0.6656
Epoch 16/100
38/38 [==============================] - 1s 15ms/step - loss: 0.4389 - categorical_accuracy: 0.8116 - val_loss: 0.8686 - val_categorical_accuracy: 0.6589
Epoch 17/100
38/38 [==============================] - 1s 17ms/step - loss: 0.4365 - categorical_accuracy: 0.8166 - val_loss: 0.8726 - val_categorical_accuracy: 0.6656
Epoch 18/100
38/38 [==============================] - 1s 15ms/step - loss: 0.4204 - categorical_accuracy: 0.8166 - val_loss: 0.8983 - val_categorical_accuracy: 0.6789
Epoch 19/100
38/38 [==============================] - 1s 17ms/step - loss: 0.4196 - categorical_accuracy: 0.8149 - val_loss: 0.8819 - val_categorical_accuracy: 0.6856
Epoch 20/100
38/38 [==============================] - 1s 16ms/step - loss: 0.4312 - categorical_accuracy: 0.8275 - val_loss: 0.8572 - val_categorical_accuracy: 0.6589
Epoch 21/100
38/38 [==============================] - 1s 14ms/step - loss: 0.4069 - categorical_accuracy: 0.8199 - val_loss: 0.9019 - val_categorical_accuracy: 0.6555
Epoch 22/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3899 - categorical_accuracy: 0.8375 - val_loss: 0.9446 - val_categorical_accuracy: 0.6622
Epoch 23/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3787 - categorical_accuracy: 0.8400 - val_loss: 0.9777 - val_categorical_accuracy: 0.6421
Epoch 24/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3898 - categorical_accuracy: 0.8325 - val_loss: 0.9427 - val_categorical_accuracy: 0.6656
Epoch 25/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3879 - categorical_accuracy: 0.8350 - val_loss: 1.0145 - val_categorical_accuracy: 0.6455
Epoch 26/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3728 - categorical_accuracy: 0.8384 - val_loss: 0.9934 - val_categorical_accuracy: 0.6589
Epoch 27/100
38/38 [==============================] - 1s 17ms/step - loss: 0.3794 - categorical_accuracy: 0.8350 - val_loss: 1.0041 - val_categorical_accuracy: 0.6689
Epoch 28/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3750 - categorical_accuracy: 0.8509 - val_loss: 1.0198 - val_categorical_accuracy: 0.6555
Epoch 29/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3667 - categorical_accuracy: 0.8434 - val_loss: 1.1143 - val_categorical_accuracy: 0.6589
Epoch 30/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3758 - categorical_accuracy: 0.8501 - val_loss: 1.0489 - val_categorical_accuracy: 0.6555
Epoch 31/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3522 - categorical_accuracy: 0.8492 - val_loss: 1.0581 - val_categorical_accuracy: 0.6488
Epoch 32/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3482 - categorical_accuracy: 0.8576 - val_loss: 1.0927 - val_categorical_accuracy: 0.6555
Epoch 33/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3399 - categorical_accuracy: 0.8601 - val_loss: 1.0551 - val_categorical_accuracy: 0.6589
Epoch 34/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3343 - categorical_accuracy: 0.8618 - val_loss: 1.1893 - val_categorical_accuracy: 0.6321
Epoch 35/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3470 - categorical_accuracy: 0.8518 - val_loss: 1.1438 - val_categorical_accuracy: 0.6421
Epoch 36/100
38/38 [==============================] - 0s 13ms/step - loss: 0.3420 - categorical_accuracy: 0.8610 - val_loss: 1.1711 - val_categorical_accuracy: 0.6555
Epoch 37/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3199 - categorical_accuracy: 0.8727 - val_loss: 1.1824 - val_categorical_accuracy: 0.6589
Epoch 38/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3156 - categorical_accuracy: 0.8710 - val_loss: 1.2320 - val_categorical_accuracy: 0.6321
Epoch 39/100
38/38 [==============================] - 1s 17ms/step - loss: 0.3287 - categorical_accuracy: 0.8610 - val_loss: 1.1874 - val_categorical_accuracy: 0.6555
Epoch 40/100
38/38 [==============================] - 1s 17ms/step - loss: 0.3356 - categorical_accuracy: 0.8635 - val_loss: 1.1754 - val_categorical_accuracy: 0.6421
Epoch 41/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3132 - categorical_accuracy: 0.8693 - val_loss: 1.2099 - val_categorical_accuracy: 0.6421
Epoch 42/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3073 - categorical_accuracy: 0.8760 - val_loss: 1.2618 - val_categorical_accuracy: 0.6355
Epoch 43/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3106 - categorical_accuracy: 0.8752 - val_loss: 1.2798 - val_categorical_accuracy: 0.6254
Epoch 44/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3090 - categorical_accuracy: 0.8610 - val_loss: 1.3274 - val_categorical_accuracy: 0.6522
Epoch 45/100
38/38 [==============================] - 1s 16ms/step - loss: 0.3196 - categorical_accuracy: 0.8702 - val_loss: 1.2613 - val_categorical_accuracy: 0.6321
Epoch 46/100
38/38 [==============================] - 1s 15ms/step - loss: 0.3019 - categorical_accuracy: 0.8710 - val_loss: 1.2919 - val_categorical_accuracy: 0.6589
Epoch 47/100
38/38 [==============================] - 1s 14ms/step - loss: 0.3123 - categorical_accuracy: 0.8719 - val_loss: 1.3520 - val_categorical_accuracy: 0.6187
Epoch 48/100
38/38 [==============================] - 1s 17ms/step - loss: 0.3066 - categorical_accuracy: 0.8752 - val_loss: 1.2630 - val_categorical_accuracy: 0.6488
Epoch 49/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2938 - categorical_accuracy: 0.8827 - val_loss: 1.3472 - val_categorical_accuracy: 0.6555
Epoch 50/100
38/38 [==============================] - 1s 15ms/step - loss: 0.2820 - categorical_accuracy: 0.8769 - val_loss: 1.3563 - val_categorical_accuracy: 0.6555
Epoch 51/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2730 - categorical_accuracy: 0.8878 - val_loss: 1.3784 - val_categorical_accuracy: 0.6421
Epoch 52/100
38/38 [==============================] - 1s 15ms/step - loss: 0.2769 - categorical_accuracy: 0.8777 - val_loss: 1.4638 - val_categorical_accuracy: 0.6254
Epoch 53/100
38/38 [==============================] - 1s 14ms/step - loss: 0.2732 - categorical_accuracy: 0.8794 - val_loss: 1.4578 - val_categorical_accuracy: 0.6221
Epoch 54/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2744 - categorical_accuracy: 0.8794 - val_loss: 1.4794 - val_categorical_accuracy: 0.6254
Epoch 55/100
38/38 [==============================] - 1s 15ms/step - loss: 0.2888 - categorical_accuracy: 0.8819 - val_loss: 1.4491 - val_categorical_accuracy: 0.6388
Epoch 56/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2876 - categorical_accuracy: 0.8802 - val_loss: 1.4744 - val_categorical_accuracy: 0.6355
Epoch 57/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2944 - categorical_accuracy: 0.8777 - val_loss: 1.3983 - val_categorical_accuracy: 0.6321
Epoch 58/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2703 - categorical_accuracy: 0.8827 - val_loss: 1.4233 - val_categorical_accuracy: 0.6388
Epoch 59/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2722 - categorical_accuracy: 0.8844 - val_loss: 1.4372 - val_categorical_accuracy: 0.6421
Epoch 60/100
38/38 [==============================] - 1s 19ms/step - loss: 0.2758 - categorical_accuracy: 0.8811 - val_loss: 1.4668 - val_categorical_accuracy: 0.6388
Epoch 61/100
38/38 [==============================] - 1s 21ms/step - loss: 0.2753 - categorical_accuracy: 0.8769 - val_loss: 1.4802 - val_categorical_accuracy: 0.6321
Epoch 62/100
38/38 [==============================] - 1s 19ms/step - loss: 0.2580 - categorical_accuracy: 0.8878 - val_loss: 1.5286 - val_categorical_accuracy: 0.6421
Epoch 63/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2599 - categorical_accuracy: 0.8878 - val_loss: 1.5043 - val_categorical_accuracy: 0.6321
Epoch 64/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2563 - categorical_accuracy: 0.8886 - val_loss: 1.6177 - val_categorical_accuracy: 0.6355
Epoch 65/100
38/38 [==============================] - 1s 15ms/step - loss: 0.2633 - categorical_accuracy: 0.8936 - val_loss: 1.6432 - val_categorical_accuracy: 0.6254
Epoch 66/100
38/38 [==============================] - 1s 20ms/step - loss: 0.2719 - categorical_accuracy: 0.8786 - val_loss: 1.6771 - val_categorical_accuracy: 0.6221
Epoch 67/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2831 - categorical_accuracy: 0.8853 - val_loss: 1.5515 - val_categorical_accuracy: 0.6321
Epoch 68/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2439 - categorical_accuracy: 0.8928 - val_loss: 1.5903 - val_categorical_accuracy: 0.6355
Epoch 69/100
38/38 [==============================] - 1s 23ms/step - loss: 0.2494 - categorical_accuracy: 0.8945 - val_loss: 1.6017 - val_categorical_accuracy: 0.6355
Epoch 70/100
38/38 [==============================] - 1s 20ms/step - loss: 0.2589 - categorical_accuracy: 0.8945 - val_loss: 1.7293 - val_categorical_accuracy: 0.6288
Epoch 71/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2514 - categorical_accuracy: 0.8869 - val_loss: 1.6308 - val_categorical_accuracy: 0.6355
Epoch 72/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2257 - categorical_accuracy: 0.9037 - val_loss: 1.7299 - val_categorical_accuracy: 0.6355
Epoch 73/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2398 - categorical_accuracy: 0.9020 - val_loss: 1.6914 - val_categorical_accuracy: 0.6388
Epoch 74/100
38/38 [==============================] - 1s 20ms/step - loss: 0.2602 - categorical_accuracy: 0.8936 - val_loss: 1.6701 - val_categorical_accuracy: 0.6321
Epoch 75/100
38/38 [==============================] - 1s 23ms/step - loss: 0.2497 - categorical_accuracy: 0.8987 - val_loss: 1.7162 - val_categorical_accuracy: 0.6221
Epoch 76/100
38/38 [==============================] - 1s 20ms/step - loss: 0.2380 - categorical_accuracy: 0.9037 - val_loss: 1.7257 - val_categorical_accuracy: 0.6288
Epoch 77/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2496 - categorical_accuracy: 0.8936 - val_loss: 1.7693 - val_categorical_accuracy: 0.6388
Epoch 78/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2596 - categorical_accuracy: 0.8961 - val_loss: 1.7423 - val_categorical_accuracy: 0.6321
Epoch 79/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2588 - categorical_accuracy: 0.8827 - val_loss: 1.7395 - val_categorical_accuracy: 0.6388
Epoch 80/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2387 - categorical_accuracy: 0.9087 - val_loss: 1.7281 - val_categorical_accuracy: 0.6388
Epoch 81/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2369 - categorical_accuracy: 0.8987 - val_loss: 1.6895 - val_categorical_accuracy: 0.6288
Epoch 82/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2211 - categorical_accuracy: 0.9045 - val_loss: 1.8346 - val_categorical_accuracy: 0.6388
Epoch 83/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2402 - categorical_accuracy: 0.8928 - val_loss: 1.8963 - val_categorical_accuracy: 0.6388
Epoch 84/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2481 - categorical_accuracy: 0.8861 - val_loss: 1.7766 - val_categorical_accuracy: 0.6221
Epoch 85/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2478 - categorical_accuracy: 0.8995 - val_loss: 1.7865 - val_categorical_accuracy: 0.6288
Epoch 86/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2203 - categorical_accuracy: 0.8995 - val_loss: 1.7670 - val_categorical_accuracy: 0.6321
Epoch 87/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2284 - categorical_accuracy: 0.9037 - val_loss: 1.9090 - val_categorical_accuracy: 0.6321
Epoch 88/100
38/38 [==============================] - 1s 19ms/step - loss: 0.2232 - categorical_accuracy: 0.8995 - val_loss: 1.9561 - val_categorical_accuracy: 0.6388
Epoch 89/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2266 - categorical_accuracy: 0.9020 - val_loss: 1.9377 - val_categorical_accuracy: 0.6221
Epoch 90/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2191 - categorical_accuracy: 0.9037 - val_loss: 1.9340 - val_categorical_accuracy: 0.6388
Epoch 91/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2350 - categorical_accuracy: 0.8995 - val_loss: 2.0119 - val_categorical_accuracy: 0.6488
Epoch 92/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2381 - categorical_accuracy: 0.9020 - val_loss: 1.9257 - val_categorical_accuracy: 0.6254
Epoch 93/100
38/38 [==============================] - 1s 18ms/step - loss: 0.2426 - categorical_accuracy: 0.8961 - val_loss: 1.8555 - val_categorical_accuracy: 0.6221
Epoch 94/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2298 - categorical_accuracy: 0.9020 - val_loss: 1.9303 - val_categorical_accuracy: 0.6254
Epoch 95/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2291 - categorical_accuracy: 0.8995 - val_loss: 1.9230 - val_categorical_accuracy: 0.6488
Epoch 96/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2042 - categorical_accuracy: 0.9079 - val_loss: 2.0179 - val_categorical_accuracy: 0.6522
Epoch 97/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2220 - categorical_accuracy: 0.8953 - val_loss: 2.1383 - val_categorical_accuracy: 0.6254
Epoch 98/100
38/38 [==============================] - 1s 16ms/step - loss: 0.2398 - categorical_accuracy: 0.8978 - val_loss: 1.9165 - val_categorical_accuracy: 0.6388
Epoch 99/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2126 - categorical_accuracy: 0.9095 - val_loss: 2.0451 - val_categorical_accuracy: 0.6388
Epoch 100/100
38/38 [==============================] - 1s 17ms/step - loss: 0.2409 - categorical_accuracy: 0.9112 - val_loss: 1.8730 - val_categorical_accuracy: 0.6288
CPU times: user 2min 1s, sys: 40 s, total: 2min 41s
Wall time: 1min 5s</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>my_CNN.accuracy_plot()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>my_CNN.loss_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-31-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>my_CNN.test_model(verbose<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 0s 10ms/step
10/10 [==============================] - 0s 9ms/step - loss: 1.8730 - categorical_accuracy: 0.6288

Model Loss from testing:
1.87295401096344

Model Accuracy from testing:
0.6287625432014465

Preview of model prediction (raw):
[[1.4808976e-06 6.4509870e-05 9.9993408e-01]
 [8.6662483e-01 4.5062302e-06 1.3337061e-01]
 [1.2503038e-07 9.9913967e-01 8.6021458e-04]
 [3.6376094e-10 4.7211987e-01 5.2788007e-01]
 [1.0000000e+00 1.9983109e-16 1.7426380e-13]]

Preview of predictions labeled:
[['science']
 ['football']
 ['politics']
 ['science']
 ['football']]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>my_CNN.pretty_confusion_matrix()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="lstm" class="level1">
<h1>LSTM</h1>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>LSTM_model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(<span class="dv">50</span>),</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>  input_shape <span class="op">=</span> input_shape),</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>  tf.keras.layers.Dense(<span class="dv">3</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-12-09 08:29:49.815851: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:49.818660: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:49.822827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:29:50.105473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:29:50.194940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:50.198242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:50.200926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>my_LSTM <span class="op">=</span> exam_model_eval(LSTM_model,model_name<span class="op">=</span><span class="st">"LSTM Model"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 bidirectional (Bidirectiona  (None, 100)              20800     
 l)                                                              
                                                                 
 dense_6 (Dense)             (None, 3)                 303       
                                                                 
=================================================================
Total params: 21,103
Trainable params: 21,103
Non-trainable params: 0
_________________________________________________________________
None</code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>my_LSTM.compile_model()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model was compiled (using following parameters):
Loss Function = &lt;keras.losses.CategoricalCrossentropy object at 0x7f5ef098e010&gt;
Accuracy Metric = CategoricalAccuracy(name=categorical_accuracy,dtype=float32)
Optimizer = &lt;keras.optimizers.legacy.adam.Adam object at 0x7f5ef0965110&gt;</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>time</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>my_LSTM.train_model(epochs<span class="op">=</span><span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/100
38/38 [==============================] - ETA: 0s - loss: 1.1016 - categorical_accuracy: 0.401238/38 [==============================] - 14s 225ms/step - loss: 1.1016 - categorical_accuracy: 0.4012 - val_loss: 1.0892 - val_categorical_accuracy: 0.3645
Epoch 2/100
38/38 [==============================] - 9s 242ms/step - loss: 1.0845 - categorical_accuracy: 0.4037 - val_loss: 1.0566 - val_categorical_accuracy: 0.3712
Epoch 3/100
38/38 [==============================] - 8s 215ms/step - loss: 1.0830 - categorical_accuracy: 0.3677 - val_loss: 1.0770 - val_categorical_accuracy: 0.3779
Epoch 4/100
38/38 [==============================] - 8s 215ms/step - loss: 1.0626 - categorical_accuracy: 0.4188 - val_loss: 1.0505 - val_categorical_accuracy: 0.4013
Epoch 5/100
38/38 [==============================] - 8s 211ms/step - loss: 1.0516 - categorical_accuracy: 0.4188 - val_loss: 1.0501 - val_categorical_accuracy: 0.4214
Epoch 6/100
38/38 [==============================] - 8s 212ms/step - loss: 1.0441 - categorical_accuracy: 0.4355 - val_loss: 1.0417 - val_categorical_accuracy: 0.4883
Epoch 7/100
38/38 [==============================] - 8s 222ms/step - loss: 1.0421 - categorical_accuracy: 0.4606 - val_loss: 1.0409 - val_categorical_accuracy: 0.4515
Epoch 8/100
38/38 [==============================] - 8s 217ms/step - loss: 1.0337 - categorical_accuracy: 0.4673 - val_loss: 1.0375 - val_categorical_accuracy: 0.5050
Epoch 9/100
38/38 [==============================] - 8s 219ms/step - loss: 1.0282 - categorical_accuracy: 0.4849 - val_loss: 1.0263 - val_categorical_accuracy: 0.4783
Epoch 10/100
38/38 [==============================] - 8s 211ms/step - loss: 1.0523 - categorical_accuracy: 0.4657 - val_loss: 1.1167 - val_categorical_accuracy: 0.3344
Epoch 11/100
38/38 [==============================] - 8s 220ms/step - loss: 1.0826 - categorical_accuracy: 0.3685 - val_loss: 1.0795 - val_categorical_accuracy: 0.4047
Epoch 12/100
38/38 [==============================] - 9s 227ms/step - loss: 1.0590 - categorical_accuracy: 0.4322 - val_loss: 1.0525 - val_categorical_accuracy: 0.4415
Epoch 13/100
38/38 [==============================] - 9s 228ms/step - loss: 1.0271 - categorical_accuracy: 0.4849 - val_loss: 1.0589 - val_categorical_accuracy: 0.4883
Epoch 14/100
38/38 [==============================] - 8s 216ms/step - loss: 1.0399 - categorical_accuracy: 0.4221 - val_loss: 1.0275 - val_categorical_accuracy: 0.4682
Epoch 15/100
38/38 [==============================] - 8s 217ms/step - loss: 1.0095 - categorical_accuracy: 0.4950 - val_loss: 1.0251 - val_categorical_accuracy: 0.4783
Epoch 16/100
38/38 [==============================] - 8s 213ms/step - loss: 1.0068 - categorical_accuracy: 0.4816 - val_loss: 1.0133 - val_categorical_accuracy: 0.4883
Epoch 17/100
38/38 [==============================] - 8s 216ms/step - loss: 0.9947 - categorical_accuracy: 0.4849 - val_loss: 1.0175 - val_categorical_accuracy: 0.4649
Epoch 18/100
38/38 [==============================] - 8s 219ms/step - loss: 0.9962 - categorical_accuracy: 0.4849 - val_loss: 0.9973 - val_categorical_accuracy: 0.5084
Epoch 19/100
38/38 [==============================] - 8s 214ms/step - loss: 1.0078 - categorical_accuracy: 0.4908 - val_loss: 1.0212 - val_categorical_accuracy: 0.4816
Epoch 20/100
38/38 [==============================] - 8s 214ms/step - loss: 1.0029 - categorical_accuracy: 0.5000 - val_loss: 1.0181 - val_categorical_accuracy: 0.4950
Epoch 21/100
38/38 [==============================] - 8s 213ms/step - loss: 0.9981 - categorical_accuracy: 0.4849 - val_loss: 1.0130 - val_categorical_accuracy: 0.5017
Epoch 22/100
38/38 [==============================] - 8s 217ms/step - loss: 0.9901 - categorical_accuracy: 0.4933 - val_loss: 1.0066 - val_categorical_accuracy: 0.5151
Epoch 23/100
38/38 [==============================] - 9s 226ms/step - loss: 0.9749 - categorical_accuracy: 0.5075 - val_loss: 0.9887 - val_categorical_accuracy: 0.5217
Epoch 24/100
38/38 [==============================] - 8s 217ms/step - loss: 0.9651 - categorical_accuracy: 0.5084 - val_loss: 0.9800 - val_categorical_accuracy: 0.5084
Epoch 25/100
38/38 [==============================] - 8s 219ms/step - loss: 0.9807 - categorical_accuracy: 0.5042 - val_loss: 1.0059 - val_categorical_accuracy: 0.5217
Epoch 26/100
38/38 [==============================] - 8s 217ms/step - loss: 0.9711 - categorical_accuracy: 0.5101 - val_loss: 1.0113 - val_categorical_accuracy: 0.5050
Epoch 27/100
38/38 [==============================] - 8s 214ms/step - loss: 0.9619 - categorical_accuracy: 0.5168 - val_loss: 0.9823 - val_categorical_accuracy: 0.4950
Epoch 28/100
38/38 [==============================] - 8s 213ms/step - loss: 0.9416 - categorical_accuracy: 0.5184 - val_loss: 0.9735 - val_categorical_accuracy: 0.5385
Epoch 29/100
38/38 [==============================] - 8s 218ms/step - loss: 0.9518 - categorical_accuracy: 0.5142 - val_loss: 0.9843 - val_categorical_accuracy: 0.5251
Epoch 30/100
38/38 [==============================] - 8s 218ms/step - loss: 0.9408 - categorical_accuracy: 0.5193 - val_loss: 0.9661 - val_categorical_accuracy: 0.5017
Epoch 31/100
38/38 [==============================] - 8s 217ms/step - loss: 0.9327 - categorical_accuracy: 0.5209 - val_loss: 0.9625 - val_categorical_accuracy: 0.5251
Epoch 32/100
38/38 [==============================] - 9s 230ms/step - loss: 0.9468 - categorical_accuracy: 0.5193 - val_loss: 0.9791 - val_categorical_accuracy: 0.4883
Epoch 33/100
38/38 [==============================] - 9s 243ms/step - loss: 0.9501 - categorical_accuracy: 0.5176 - val_loss: 0.9660 - val_categorical_accuracy: 0.4983
Epoch 34/100
38/38 [==============================] - 8s 221ms/step - loss: 0.9359 - categorical_accuracy: 0.5402 - val_loss: 0.9742 - val_categorical_accuracy: 0.4783
Epoch 35/100
38/38 [==============================] - 8s 220ms/step - loss: 0.9357 - categorical_accuracy: 0.5260 - val_loss: 0.9659 - val_categorical_accuracy: 0.5251
Epoch 36/100
38/38 [==============================] - 8s 215ms/step - loss: 0.9151 - categorical_accuracy: 0.5528 - val_loss: 0.9640 - val_categorical_accuracy: 0.4849
Epoch 37/100
38/38 [==============================] - 8s 216ms/step - loss: 0.9060 - categorical_accuracy: 0.5394 - val_loss: 0.9636 - val_categorical_accuracy: 0.4883
Epoch 38/100
38/38 [==============================] - 9s 242ms/step - loss: 0.9269 - categorical_accuracy: 0.5369 - val_loss: 0.9614 - val_categorical_accuracy: 0.5385
Epoch 39/100
38/38 [==============================] - 9s 245ms/step - loss: 0.8973 - categorical_accuracy: 0.5444 - val_loss: 0.9362 - val_categorical_accuracy: 0.5284
Epoch 40/100
38/38 [==============================] - 9s 241ms/step - loss: 0.9126 - categorical_accuracy: 0.5302 - val_loss: 0.9210 - val_categorical_accuracy: 0.5284
Epoch 41/100
38/38 [==============================] - 9s 246ms/step - loss: 0.8867 - categorical_accuracy: 0.5469 - val_loss: 0.9219 - val_categorical_accuracy: 0.5452
Epoch 42/100
38/38 [==============================] - 9s 240ms/step - loss: 0.8726 - categorical_accuracy: 0.5536 - val_loss: 0.9165 - val_categorical_accuracy: 0.5552
Epoch 43/100
38/38 [==============================] - 9s 246ms/step - loss: 0.8880 - categorical_accuracy: 0.5561 - val_loss: 0.9414 - val_categorical_accuracy: 0.5017
Epoch 44/100
38/38 [==============================] - 10s 255ms/step - loss: 0.9263 - categorical_accuracy: 0.5427 - val_loss: 0.9635 - val_categorical_accuracy: 0.5084
Epoch 45/100
38/38 [==============================] - 10s 254ms/step - loss: 0.9112 - categorical_accuracy: 0.5519 - val_loss: 0.9580 - val_categorical_accuracy: 0.5117
Epoch 46/100
38/38 [==============================] - 8s 224ms/step - loss: 0.8893 - categorical_accuracy: 0.5561 - val_loss: 0.9483 - val_categorical_accuracy: 0.5351
Epoch 47/100
38/38 [==============================] - 9s 226ms/step - loss: 0.8854 - categorical_accuracy: 0.5620 - val_loss: 0.9326 - val_categorical_accuracy: 0.5485
Epoch 48/100
38/38 [==============================] - 8s 224ms/step - loss: 0.8763 - categorical_accuracy: 0.5561 - val_loss: 0.9382 - val_categorical_accuracy: 0.5452
Epoch 49/100
38/38 [==============================] - 8s 219ms/step - loss: 0.8720 - categorical_accuracy: 0.5628 - val_loss: 0.9374 - val_categorical_accuracy: 0.5284
Epoch 50/100
38/38 [==============================] - 8s 222ms/step - loss: 0.8755 - categorical_accuracy: 0.5687 - val_loss: 0.9544 - val_categorical_accuracy: 0.5151
Epoch 51/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8988 - categorical_accuracy: 0.5494 - val_loss: 0.9797 - val_categorical_accuracy: 0.4849
Epoch 52/100
38/38 [==============================] - 9s 234ms/step - loss: 0.9161 - categorical_accuracy: 0.5528 - val_loss: 0.9316 - val_categorical_accuracy: 0.5351
Epoch 53/100
38/38 [==============================] - 9s 227ms/step - loss: 0.8796 - categorical_accuracy: 0.5402 - val_loss: 0.9310 - val_categorical_accuracy: 0.5385
Epoch 54/100
38/38 [==============================] - 9s 228ms/step - loss: 0.8847 - categorical_accuracy: 0.5570 - val_loss: 0.9391 - val_categorical_accuracy: 0.5318
Epoch 55/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8678 - categorical_accuracy: 0.5695 - val_loss: 0.9113 - val_categorical_accuracy: 0.5552
Epoch 56/100
38/38 [==============================] - 9s 225ms/step - loss: 0.8749 - categorical_accuracy: 0.5586 - val_loss: 0.9225 - val_categorical_accuracy: 0.5485
Epoch 57/100
38/38 [==============================] - 9s 228ms/step - loss: 0.8593 - categorical_accuracy: 0.5812 - val_loss: 0.8972 - val_categorical_accuracy: 0.5552
Epoch 58/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8471 - categorical_accuracy: 0.5863 - val_loss: 0.8960 - val_categorical_accuracy: 0.5786
Epoch 59/100
38/38 [==============================] - 9s 227ms/step - loss: 0.8450 - categorical_accuracy: 0.5796 - val_loss: 0.8863 - val_categorical_accuracy: 0.6054
Epoch 60/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8510 - categorical_accuracy: 0.5745 - val_loss: 0.9111 - val_categorical_accuracy: 0.5652
Epoch 61/100
38/38 [==============================] - 9s 232ms/step - loss: 0.8444 - categorical_accuracy: 0.5804 - val_loss: 0.9257 - val_categorical_accuracy: 0.5552
Epoch 62/100
38/38 [==============================] - 9s 226ms/step - loss: 0.8718 - categorical_accuracy: 0.5754 - val_loss: 0.9122 - val_categorical_accuracy: 0.5786
Epoch 63/100
38/38 [==============================] - 9s 226ms/step - loss: 0.8481 - categorical_accuracy: 0.5678 - val_loss: 0.9015 - val_categorical_accuracy: 0.5953
Epoch 64/100
38/38 [==============================] - 9s 233ms/step - loss: 0.8483 - categorical_accuracy: 0.5754 - val_loss: 0.8978 - val_categorical_accuracy: 0.5819
Epoch 65/100
38/38 [==============================] - 9s 228ms/step - loss: 0.8404 - categorical_accuracy: 0.5905 - val_loss: 0.9366 - val_categorical_accuracy: 0.5652
Epoch 66/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8416 - categorical_accuracy: 0.5846 - val_loss: 0.8937 - val_categorical_accuracy: 0.5886
Epoch 67/100
38/38 [==============================] - 9s 235ms/step - loss: 0.8213 - categorical_accuracy: 0.5946 - val_loss: 0.8796 - val_categorical_accuracy: 0.5753
Epoch 68/100
38/38 [==============================] - 9s 234ms/step - loss: 0.8722 - categorical_accuracy: 0.5745 - val_loss: 0.9299 - val_categorical_accuracy: 0.5619
Epoch 69/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8559 - categorical_accuracy: 0.5645 - val_loss: 0.8995 - val_categorical_accuracy: 0.5853
Epoch 70/100
38/38 [==============================] - 9s 232ms/step - loss: 0.8292 - categorical_accuracy: 0.5863 - val_loss: 0.9092 - val_categorical_accuracy: 0.5819
Epoch 71/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8180 - categorical_accuracy: 0.6080 - val_loss: 0.8933 - val_categorical_accuracy: 0.6054
Epoch 72/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8214 - categorical_accuracy: 0.5879 - val_loss: 0.8921 - val_categorical_accuracy: 0.5953
Epoch 73/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8095 - categorical_accuracy: 0.5946 - val_loss: 0.8779 - val_categorical_accuracy: 0.5987
Epoch 74/100
38/38 [==============================] - 9s 226ms/step - loss: 0.8111 - categorical_accuracy: 0.5980 - val_loss: 0.8962 - val_categorical_accuracy: 0.5853
Epoch 75/100
38/38 [==============================] - 9s 228ms/step - loss: 0.8097 - categorical_accuracy: 0.6030 - val_loss: 0.9065 - val_categorical_accuracy: 0.5753
Epoch 76/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8054 - categorical_accuracy: 0.5997 - val_loss: 0.9072 - val_categorical_accuracy: 0.5753
Epoch 77/100
38/38 [==============================] - 9s 242ms/step - loss: 0.8134 - categorical_accuracy: 0.5938 - val_loss: 0.9375 - val_categorical_accuracy: 0.5585
Epoch 78/100
38/38 [==============================] - 9s 238ms/step - loss: 0.8095 - categorical_accuracy: 0.6039 - val_loss: 0.8909 - val_categorical_accuracy: 0.6087
Epoch 79/100
38/38 [==============================] - 9s 231ms/step - loss: 0.8007 - categorical_accuracy: 0.5963 - val_loss: 0.9023 - val_categorical_accuracy: 0.5786
Epoch 80/100
38/38 [==============================] - 9s 232ms/step - loss: 0.8019 - categorical_accuracy: 0.5988 - val_loss: 0.8919 - val_categorical_accuracy: 0.5786
Epoch 81/100
38/38 [==============================] - 9s 232ms/step - loss: 0.7882 - categorical_accuracy: 0.6198 - val_loss: 0.9237 - val_categorical_accuracy: 0.5686
Epoch 82/100
38/38 [==============================] - 9s 225ms/step - loss: 0.7964 - categorical_accuracy: 0.6047 - val_loss: 0.9141 - val_categorical_accuracy: 0.5686
Epoch 83/100
38/38 [==============================] - 9s 228ms/step - loss: 0.7932 - categorical_accuracy: 0.6022 - val_loss: 0.9235 - val_categorical_accuracy: 0.5753
Epoch 84/100
38/38 [==============================] - 9s 231ms/step - loss: 0.7857 - categorical_accuracy: 0.6055 - val_loss: 0.9277 - val_categorical_accuracy: 0.5652
Epoch 85/100
38/38 [==============================] - 9s 228ms/step - loss: 0.8092 - categorical_accuracy: 0.5988 - val_loss: 0.9599 - val_categorical_accuracy: 0.5619
Epoch 86/100
38/38 [==============================] - 9s 227ms/step - loss: 0.8071 - categorical_accuracy: 0.5997 - val_loss: 0.9024 - val_categorical_accuracy: 0.5920
Epoch 87/100
38/38 [==============================] - 9s 232ms/step - loss: 0.7924 - categorical_accuracy: 0.6114 - val_loss: 0.9275 - val_categorical_accuracy: 0.6020
Epoch 88/100
38/38 [==============================] - 9s 230ms/step - loss: 0.8370 - categorical_accuracy: 0.5796 - val_loss: 1.6367 - val_categorical_accuracy: 0.4080
Epoch 89/100
38/38 [==============================] - 9s 230ms/step - loss: 0.9328 - categorical_accuracy: 0.5251 - val_loss: 1.0075 - val_categorical_accuracy: 0.4983
Epoch 90/100
38/38 [==============================] - 9s 231ms/step - loss: 0.9149 - categorical_accuracy: 0.5352 - val_loss: 1.0351 - val_categorical_accuracy: 0.5151
Epoch 91/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8975 - categorical_accuracy: 0.5436 - val_loss: 0.9948 - val_categorical_accuracy: 0.5017
Epoch 92/100
38/38 [==============================] - 9s 233ms/step - loss: 0.8967 - categorical_accuracy: 0.5486 - val_loss: 1.0299 - val_categorical_accuracy: 0.4950
Epoch 93/100
38/38 [==============================] - 9s 231ms/step - loss: 0.9047 - categorical_accuracy: 0.5377 - val_loss: 1.0285 - val_categorical_accuracy: 0.4916
Epoch 94/100
38/38 [==============================] - 9s 246ms/step - loss: 0.8985 - categorical_accuracy: 0.5519 - val_loss: 1.0119 - val_categorical_accuracy: 0.4983
Epoch 95/100
38/38 [==============================] - 9s 237ms/step - loss: 0.9061 - categorical_accuracy: 0.5335 - val_loss: 1.0064 - val_categorical_accuracy: 0.5017
Epoch 96/100
38/38 [==============================] - 9s 227ms/step - loss: 0.8932 - categorical_accuracy: 0.5302 - val_loss: 0.9921 - val_categorical_accuracy: 0.5284
Epoch 97/100
38/38 [==============================] - 9s 229ms/step - loss: 0.8858 - categorical_accuracy: 0.5586 - val_loss: 1.0137 - val_categorical_accuracy: 0.5050
Epoch 98/100
38/38 [==============================] - 9s 235ms/step - loss: 0.8785 - categorical_accuracy: 0.5561 - val_loss: 1.0118 - val_categorical_accuracy: 0.4816
Epoch 99/100
38/38 [==============================] - 9s 239ms/step - loss: 0.9123 - categorical_accuracy: 0.5494 - val_loss: 0.9989 - val_categorical_accuracy: 0.5084
Epoch 100/100
38/38 [==============================] - 10s 253ms/step - loss: 0.9021 - categorical_accuracy: 0.5452 - val_loss: 0.9898 - val_categorical_accuracy: 0.5151
CPU times: user 50min 13s, sys: 14min 48s, total: 1h 5min 2s
Wall time: 14min 28s</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-12-09 08:29:50.854903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:50.859828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:50.862129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:29:51.115414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:29:51.273509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:51.277900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:51.281980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:29:52.196934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:29:52.902274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:52.909102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:52.913336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:29:53.262246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:29:53.440306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:29:53.446167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:29:53.451913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:29:54.599477: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:30:02.900282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:30:02.904083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:30:02.907014: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:30:03.113554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:30:03.211651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:30:03.213592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:30:03.215389: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>my_LSTM.accuracy_plot()</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>my_LSTM.loss_plot()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-38-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-38-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>my_LSTM.test_model(verbose<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2023-12-09 08:44:20.510807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:44:20.519733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:44:20.524959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-12-09 08:44:20.881161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]
     [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]
2023-12-09 08:44:20.974544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32
     [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-12-09 08:44:20.978469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32
     [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-12-09 08:44:20.983097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32
     [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 [==============================] - 2s 70ms/step
10/10 [==============================] - 1s 90ms/step - loss: 0.9898 - categorical_accuracy: 0.5151

Model Loss from testing:
0.9897634387016296

Model Accuracy from testing:
0.5150501728057861

Preview of model prediction (raw):
[[0.25686276 0.58602667 0.15711057]
 [0.36523157 0.2252316  0.40953684]
 [0.19448712 0.3848234  0.42068952]
 [0.03716486 0.32854217 0.63429296]
 [0.31666362 0.2699188  0.41341752]]

Preview of predictions labeled:
[['politics']
 ['science']
 ['science']
 ['science']
 ['science']]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>my_LSTM.pretty_confusion_matrix()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="JasmineKobayashi_NN_Exam_2023_files/figure-html/cell-40-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>